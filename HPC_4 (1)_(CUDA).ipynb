{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSdrnLJ7Bvq",
        "outputId": "c6177522-fd36-4d0f-e39c-0a82cf4eed25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "# Check CUDA version\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install CUDA package\n",
        "!pip install git+https://github.com/afnan47/cuda.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5RoQIcS9qVQ",
        "outputId": "b56d3166-eb9b-4180-9235-a9df06248212"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/afnan47/cuda.git\n",
            "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-ty9zr79n\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-ty9zr79n\n",
            "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4289 sha256=44a48b64e57884a41828559a3b7b7f1814ffa2583898e520f9208883274076a8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-33werrxw/wheels/aa/f3/44/e10c1d226ec561d971fcd4b0463f6bff08602afa928a3e7bc7\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load nvcc plugin\n",
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwS1ZZjT-A7Y",
        "outputId": "53c9f453-44ee-4176-a20b-ec8e4a1df740"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sum.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <climits>\n",
        "\n",
        "__global__ void min_reduction_kernel(int* arr, int size, int* result) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        atomicMin(result, arr[tid]);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void max_reduction_kernel(int* arr, int size, int* result) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        atomicMax(result, arr[tid]);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sum_reduction_kernel(int* arr, int size, int* result) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        atomicAdd(result, arr[tid]);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void average_reduction_kernel(int* arr, int size, int* sum) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        atomicAdd(sum, arr[tid]);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    std::vector<int> arr = {5, 2, 9, 1, 7, 6, 8, 3, 4};\n",
        "    int size = arr.size();\n",
        "    int* d_arr;\n",
        "    int* d_result;\n",
        "    int result_min = INT_MAX;\n",
        "    int result_max = INT_MIN;\n",
        "    int result_sum = 0;\n",
        "\n",
        "    // Allocate memory on the device\n",
        "    cudaMalloc(&d_arr, size * sizeof(int));\n",
        "    cudaMalloc(&d_result, sizeof(int));\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(d_arr, arr.data(), size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_result, &result_min, sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Perform min reduction\n",
        "    min_reduction_kernel<<<(size + 255) / 256, 256>>>(d_arr, size, d_result);\n",
        "    cudaMemcpy(&result_min, d_result, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    std::cout << \"Minimum value: \" << result_min << std::endl;\n",
        "\n",
        "    // Perform max reduction\n",
        "    cudaMemcpy(d_result, &result_max, sizeof(int), cudaMemcpyHostToDevice);\n",
        "    max_reduction_kernel<<<(size + 255) / 256, 256>>>(d_arr, size, d_result);\n",
        "    cudaMemcpy(&result_max, d_result, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    std::cout << \"Maximum value: \" << result_max << std::endl;\n",
        "\n",
        "    // Perform sum reduction\n",
        "    cudaMemcpy(d_result, &result_sum, sizeof(int), cudaMemcpyHostToDevice);\n",
        "    sum_reduction_kernel<<<(size + 255) / 256, 256>>>(d_arr, size, d_result);\n",
        "    cudaMemcpy(&result_sum, d_result, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    std::cout << \"Sum: \" << result_sum << std::endl;\n",
        "\n",
        "    // Perform average reduction\n",
        "    cudaMemcpy(d_result, &result_sum, sizeof(int), cudaMemcpyHostToDevice);\n",
        "    average_reduction_kernel<<<(size + 255) / 256, 256>>>(d_arr, size, d_result);\n",
        "    cudaMemcpy(&result_sum, d_result, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    std::cout << \"Average: \" << static_cast<double>(result_sum) / size << std::endl;\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_arr);\n",
        "    cudaFree(d_result);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3cd_CGw-FSa",
        "outputId": "83592c2c-c825-47e2-f45d-bc340245f148"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sum.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc sum.cu -o sum\n",
        "!./sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1PMVMzF_1iN",
        "outputId": "f3760134-a686-448a-d48b-56650da94710"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value: 1\n",
            "Maximum value: 9\n",
            "Sum: 45\n",
            "Average: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add.cu\n",
        "\n",
        "\n",
        "#include <iostream>\n",
        "\n",
        "__global__ void arradd(int *x, int *y, int *z)\n",
        "{\n",
        "    int id = blockIdx.x;\n",
        "    z[id] = x[id] + y[id];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int size = 6;\n",
        "    int a[size], b[size], c[size];\n",
        "\n",
        "    std::cout << \"Enter six elements of first array:\\n\";\n",
        "    for (int i = 0; i < size; i++)\n",
        "    {\n",
        "        std::cin >> a[i];\n",
        "    }\n",
        "\n",
        "    std::cout << \"Enter six elements of second array:\\n\";\n",
        "    for (int i = 0; i < size; i++)\n",
        "    {\n",
        "        std::cin >> b[i];\n",
        "    }\n",
        "\n",
        "    int *d, *e, *f;\n",
        "\n",
        "    cudaMalloc((void **)&d, size * sizeof(int));\n",
        "    cudaMalloc((void **)&e, size * sizeof(int));\n",
        "    cudaMalloc((void **)&f, size * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d, a, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(e, b, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    arradd<<<size, 1>>>(d, e, f);\n",
        "\n",
        "    cudaMemcpy(c, f, size * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    std::cout << \"Sum of two arrays:\\n\";\n",
        "    for (int i = 0; i < size; i++)\n",
        "    {\n",
        "        std::cout << c[i] << \"\\t\";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    cudaFree(d);\n",
        "    cudaFree(e);\n",
        "    cudaFree(f);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN3p_jHz_8eu",
        "outputId": "2f2b4187-fa4b-4999-cbf3-3b9ed3e00b59"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc add.cu -o add\n",
        "!./add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN2fgUI2AVU5",
        "outputId": "d31a5c7f-92b3-469c-beb9-fffd8de609dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter six elements of first array:\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "Enter six elements of second array:\n",
            "8\n",
            "7\n",
            "5\n",
            "4\n",
            "3\n",
            "1\n",
            "Sum of two arrays:\n",
            "9\t9\t8\t8\t8\t7\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WsM2xYpkAsJT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}